{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Univariate Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\nfrom pandas import read_csv\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n# load data\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\n# feature extraction\ntest = SelectKBest(score_func=chi2, k=4)\nfit = test.fit(X, Y)\n# summarize scores\nset_printoptions(precision=3)\nprint(fit.scores_)\nfeatures = fit.transform(X)\n\n\n#For regression: f_regression, mutual_info_regression\n#For classification: chi2, f_classif, mutual_info_classif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Recursive Feature Elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Extraction with RFE\nfrom pandas import read_csv\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n# load data\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\n# feature extraction\nmodel = LogisticRegression(max_iter=400)\nrfe = RFE(model, 3)\nfit = rfe.fit(X, Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Num Features: \nfit.n_features_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selected Features:\nfit.support_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Ranking:\nfit.ranking_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature Importance using Decision Tree"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Feature Importance with Extra Trees Classifier\nfrom pandas import read_csv\nfrom sklearn.tree import  DecisionTreeClassifier\n# load data\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\n# feature extraction\nmodel = DecisionTreeClassifier()\nmodel.fit(X, Y)\nprint(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}